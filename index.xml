<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AICell Lab</title><link>https://aicell.io/</link><atom:link href="https://aicell.io/index.xml" rel="self" type="application/rss+xml"/><description>AICell Lab</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate><image><url>https://aicell.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>AICell Lab</title><link>https://aicell.io/</link></image><item><title>Example Talk</title><link>https://aicell.io/talk/example-talk/</link><pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate><guid>https://aicell.io/talk/example-talk/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click on the &lt;strong>Slides&lt;/strong> button above to view the built-in slides feature.
&lt;/div>
&lt;/div>
&lt;p>Slides can be added in a few ways:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Create&lt;/strong> slides using Wowchemy&amp;rsquo;s &lt;a href="https://wowchemy.com/docs/managing-content/#create-slides" target="_blank" rel="noopener">&lt;em>Slides&lt;/em>&lt;/a> feature and link using &lt;code>slides&lt;/code> parameter in the front matter of the talk file&lt;/li>
&lt;li>&lt;strong>Upload&lt;/strong> an existing slide deck to &lt;code>static/&lt;/code> and link using &lt;code>url_slides&lt;/code> parameter in the front matter of the talk file&lt;/li>
&lt;li>&lt;strong>Embed&lt;/strong> your slides (e.g. Google Slides) or presentation video on this page using &lt;a href="https://wowchemy.com/docs/writing-markdown-latex/" target="_blank" rel="noopener">shortcodes&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>Further event details, including &lt;a href="https://wowchemy.com/docs/writing-markdown-latex/" target="_blank" rel="noopener">page elements&lt;/a> such as image galleries, can be added to the body of this page.&lt;/p></description></item><item><title>About the AICell Lab</title><link>https://aicell.io/about/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/about/</guid><description>&lt;p>The AICell Lab is an interdisciplinary group which focuses on building AI systems for cell and molecular biology.&lt;/p>
&lt;p>We would like to take the grand challenge of modeling the human cell and building human cell simulators using powerful AI models. It is an ambitious goal that requires profound innovations in not only data analysis and modeling, but also in data generation. We believe it is crucial for us to build autonomous systems to acquire massive amounts of high quality data that are suitable to train AI models. To this front, we would like to build a fully automated imaging farm which consists of multiple microscopes, robotic arms, liquid handling robots and automatic incubators. Importantly, we run AI models in real-time to augment the microscopy views, generating artificial labels and annotations. It also allows generating feedback signals to or example, control the cell growth, differentiation, and drive the microscope to change field-of-views, illumination power and other experimental conditions in order to optimize the phototoxicity and capture rare events in live cells.&lt;/p>
&lt;p>Overall, the long-term goal of the group is to create large-scale whole human cell models trained on existing multi-omics datasets and new data generated by the imaging farm. We envision the human cell models have a great potential in &lt;em>in-silico&lt;/em> cell experimentation, drug discovery and contributing to a holistic and systematic understanding of the human cell.&lt;/p></description></item><item><title>BioImage Model Zoo</title><link>https://aicell.io/project/model-zoo/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/project/model-zoo/</guid><description>&lt;p>Deep learning-based approaches are revolutionizing imaging-driven scientific research. However, the accessibility and reproducibility of deep learning-based workflows for imaging scientists remain far from sufficient. Several tools have recently risen to the challenge of democratizing deep learning by providing user-friendly interfaces to analyze new data with pre-trained or fine-tuned models. Still, few of the existing pre-trained models are interoperable between these tools, critically restricting a modelâ€™s overall utility and the possibility of validating and reproducing scientific analyses. Here, we present the BioImage Model Zoo (&lt;a href="https://bioimage.io" target="_blank" rel="noopener">https://bioimage.io&lt;/a>): a community-driven, fully open resource where standardized pre-trained models can be shared, explored, tested, and downloaded for further adaptation or direct deployment in multiple end user-facing tools (e.g., ilastik, deepImageJ, QuPath, StarDist, ImJoy, ZeroCostDL4Mic, CSBDeep). To enable everyone to contribute and consume the Zoo resources, we provide a model standard to enable cross-compatibility, a rich list of example models and practical use-cases, developer tools, documentation, and the accompanying infrastructure for model upload, download and testing. Our contribution aims to lay the groundwork to make deep learning methods for microscopy imaging findable, accessible, interoperable, and reusable (FAIR) across software tools and platforms.&lt;/p>
&lt;p>For more details, see our publication &lt;a href="https://www.biorxiv.org/content/10.1101/2022.06.07.495102v1" target="_blank" rel="noopener">here&lt;/a>.&lt;/p></description></item><item><title>Human Cell Simulator</title><link>https://aicell.io/project/human-cell-simulator/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/project/human-cell-simulator/</guid><description>&lt;p>Whole-cell modeling enables a holistic and quantitative view of cell biology and allows performing in-silico experimentation which has a great potential in revolutionizing system biology, synthetic biology, medicine and other applications in life science. However, modeling the entire cell is an extremely complex task and is heavily limited by our understanding of the biological systems. As a newly formed research group, we would like to take the grand challenge of building a human cell simulator through recent advances in multi-omics data generation and artificial intelligence. Our aim is to use recent deep learning techniques such as convolutional neural networks, transformers, AlphaFold and diffusion models to analysis existing multi-omics dataset, combining them with massive amount of newly generated live cell, multiplexed images, to model cellular behavior through generative and predictive models.&lt;/p></description></item><item><title>ImJoy - Web Data Analysis</title><link>https://aicell.io/project/imjoy/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/project/imjoy/</guid><description>&lt;p>Deep learning (DL) methods achieve breakthrough performances in analyzing biomedical data across countless tasks, including medical diagnostics, DNA sequence analysis, augmented microscopy and drug design. Combined with increasing data repositories in genomics, imaging and other fields, such successes underlay a growing demand to adapt DL methods to new datasets and questions1. However, the dissemination of DL approaches faces considerable hurdles. Most published DL studies2,3,4,5 require users to retrain models on their own data to obtain the best performance and/or avoid erroneous results. Although trained models are frequently available through web applications or ImageJ plugins, retraining is typically only possible via scripts or command lines, rather than graphical user interfaces (GUIs). In addition, the complexities of setting up the required hardware and software environments often constitute forbidding obstacles6. Furthermore, the large datasets and computational resources typical of current DL successes pose challenges to traditional desktop-oriented software that tightly couple GUI and computation. Cloud services can partly alleviate these difficulties, but raise privacy and confidentiality issues that can be prohibitive for medical data7. Meanwhile, deploying scientific software to mobile platforms can make them accessible to billions of people8, enabling large-scale biomedical research and citizen science. These opportunities and challenges call for new computational frameworks.&lt;/p>
&lt;p>For more information, read our publication on &lt;a href="https://www.nature.com/articles/s41592-019-0627-0" target="_blank" rel="noopener">Nature Methods&lt;/a>.&lt;/p></description></item><item><title>Reef - Automated Imaging Farm</title><link>https://aicell.io/project/reef-imaging-farm/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/project/reef-imaging-farm/</guid><description>&lt;p>The aim of the project is to build a smart microscopy imaging farm for massive production of image data. It consists of multiple microscopes and fluidic systems, robotic arms, liquid handling robots and automatic incubators. The farm will be used for performing automated widefield/fluorescence imaging, long-term live cell imaging, tracking, spatial-omics and multiplexing imaging. With the AI-powered control software, data are analyzed in real-time, augmented views are added on the fly. By generating feedback control signals to control the microscope, the software will automatically change field-of-views, illumination power and other experimental conditions in order to optimize the phototoxicity and capture rare events in live cells.&lt;/p></description></item><item><title>Self-driving Microscope</title><link>https://aicell.io/project/self-driving-microscope/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/project/self-driving-microscope/</guid><description>&lt;p>The aim of the project is to develop an AI-powered self-driving microscopy system for studying cellular response under genetic and environmental stressors. The project will also be supported by the WASP-DDLS collaboration, and closely collaborate with the JaldÃ©n group at KTH. The JaldÃ©n group has rich experience in computer vision and automatic control systems. The work will also be supported by the Lundberg group under the Human Protein Atlas, which is a unique world-leading effort to map all the human proteins in cells, tissues, and organs in the human body. By joining the force with the JaldÃ©n group and Lundberg group, we would like to develop an AI-powered imaging system to continuously monitor, actively acquire and track human cells under different cellular and environmental stressors. The data will be used to train large-scale AI models to study cellular responses and make predictions for cell fate.&lt;/p></description></item><item><title>An Open-Source Modular Framework for Automated Pipetting and Imaging Applications</title><link>https://aicell.io/publication/ouyang-2022-open/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/ouyang-2022-open/</guid><description/></item><item><title>Analysis of the human protein atlas weakly supervised single-cell classification competition</title><link>https://aicell.io/publication/le-2022-analysis/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/le-2022-analysis/</guid><description/></item><item><title>BioImage Model Zoo: A Community-Driven Resource for Accessible Deep Learning in BioImage Analysis</title><link>https://aicell.io/publication/ouyang-2022-bioimage/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/ouyang-2022-bioimage/</guid><description/></item><item><title>FISH-quant v2: a scalable and modular tool for smFISH image analysis</title><link>https://aicell.io/publication/imbert-2022-fish/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/imbert-2022-fish/</guid><description/></item><item><title>ShareLoc-an open platform for sharing localization microscopy data</title><link>https://aicell.io/publication/ouyang-2022-shareloc/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/ouyang-2022-shareloc/</guid><description/></item><item><title>Subcellular mapping of the protein landscape of SARS-CoV-2 infected cells for target-centric drug repurposing</title><link>https://aicell.io/publication/kaimal-2022-subcellular/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/kaimal-2022-subcellular/</guid><description/></item><item><title>Uncovering molecular grammars of intrinsically disordered regions that organize nucleolar fibrillar centers</title><link>https://aicell.io/publication/king-2022-uncovering/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/king-2022-uncovering/</guid><description/></item><item><title>Slides</title><link>https://aicell.io/slides/imjoy/</link><pubDate>Fri, 05 Feb 2021 00:00:00 +0000</pubDate><guid>https://aicell.io/slides/imjoy/</guid><description>&lt;h2 id="imjoy-supercharging-interactivity-and-scalability-for-bioimage-analysis">ImJoy: Supercharging Interactivity and Scalability for BioImage Analysis&lt;/h2>
&lt;p>Wei Ouyang&lt;/p>
&lt;p>KTH | SciLifeLab, Stockholm&lt;/p>
&lt;hr>
&lt;h2 id="challenges-in-ai-for-bioimaging">Challenges in AI for bioimaging&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Usability&lt;/strong>: User friendly GUI&lt;/li>
&lt;li>&lt;strong>Flexibility&lt;/strong>: Flexible for different data types&lt;/li>
&lt;li>&lt;strong>Interactivity&lt;/strong>: Respond to GUI on laptop/mobile&lt;/li>
&lt;li>&lt;strong>Scalability&lt;/strong>: Remote storage and compute resources&lt;/li>
&lt;li>&lt;strong>Privacy&lt;/strong>: Edge computing&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="progressive-web-app">Progressive Web App&lt;/h2>
&lt;ul>
&lt;li>Rich and interactive UI libraries&lt;/li>
&lt;li>Computation in the browser (+cloud)&lt;/li>
&lt;li>Offline support&lt;/li>
&lt;/ul>
&lt;hr>
&lt;!-- .slide: data-background="white" -->
&lt;h3 id="imjoy-httpsimjoyio">ImJoy &lt;a href="https://imjoy.io" target="_blank" rel="noopener">https://imjoy.io&lt;/a>&lt;/h3>
&lt;p>Data science tools in the browser&lt;/p>
&lt;img src="https://docs.google.com/drawings/d/e/2PACX-1vSBsdhDBrp4L2zWfL_9YOUHCS2zQ51HtjplGa-l_a1hMpNjbqENzmXrcSmYs6yed_NACNZSRH-7qsph/pub?w=1248&amp;amp;h=573">
---
# Key concepts
* Sandboxed plugins connected via Remote Procedure calls
* Workflow composition via asynchronous programming
* Open Integration with existing software/website
&lt;hr>
&lt;h3 id="open-integration-with-web-apps">ðŸ‘Open Integration with Web Apps&lt;/h3>
&lt;p>Customize annotation workflow with Kaibu&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// load the web app via its URL
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nx">viewer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kr">await&lt;/span> &lt;span class="nx">api&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">createWindow&lt;/span>&lt;span class="p">({&lt;/span>&lt;span class="nx">src&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;https://kaibu.org/#/app&amp;#34;&lt;/span>&lt;span class="p">})&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// call api functions directly via RPC
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// add an image layer
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="kr">await&lt;/span> &lt;span class="nx">viewer&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">view_image&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;https://images.proteinatlas.org/61448/1319_C10_2_blue_red_green.jpg&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// add an annotation layer
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="kr">await&lt;/span> &lt;span class="nx">viewer&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">add_shapes&lt;/span>&lt;span class="p">([],&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="nx">name&lt;/span>&lt;span class="o">:&lt;/span>&lt;span class="s2">&amp;#34;annotation&amp;#34;&lt;/span>&lt;span class="p">})&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h3 id="demo-visualization-with-vizarr">ðŸ”¥Demo: Visualization with Vizarr&lt;/h3>
&lt;p>Made by Trevor Manz et. al.&lt;/p>
&lt;iframe width="100%" height="500px" src="https://hms-dbmi.github.io/vizarr/?source=https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.1/4495402.zarr" frameborder="0" allowfullscreen>&lt;/iframe>
&lt;hr>
&lt;h2 id="a-rapid-growing-list-of-plugins">ðŸš€A rapid growing list of plugins&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://ij.imjoy.io" target="_blank" rel="noopener">ImageJ.JS&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://imjoy-team.github.io/elFinder/" target="_blank" rel="noopener">File Manager&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/hms-dbmi/vizarr" target="_blank" rel="noopener">Vizarr&lt;/a> for visualizing zarr images&lt;/li>
&lt;li>&lt;a href="https://kitware.github.io/itk-vtk-viewer/docs/" target="_blank" rel="noopener">ITK/VTK Viewer&lt;/a> for 3D visualizing&lt;/li>
&lt;li>&lt;a href="https://slides.imjoy.io" target="_blank" rel="noopener">ImJoy Slides&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://chart.imjoy.io" target="_blank" rel="noopener">ImJoy Chart Editor&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="works-with-jupyterbinder-and-colab">Works with Jupyter/Binder and Colab&lt;/h3>
&lt;img style="height:70%;object-fit:contain;background-color: white;" src="https://raw.githubusercontent.com/imjoy-team/imjoy-demo-assets/main/image125.gif">
&lt;hr>
&lt;h2 id="conclusions">Conclusions&lt;/h2>
&lt;ul>
&lt;li>ImJoy is built for scalability and interactivity&lt;/li>
&lt;li>ImJoy plugins are sandbox services connected via RPC&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="acknowledgements">Acknowledgements&lt;/h3>
&lt;p>Work carried out at Cell Profiling group @ SciLifeLab headed by Emma Lundberg&lt;/p>
&lt;hr>
&lt;h1 id="thank-you">ðŸ™Thank You!&lt;/h1></description></item><item><title>A multi-scale map of cell structure fusing protein images and interactions</title><link>https://aicell.io/publication/qin-2021-multi/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/qin-2021-multi/</guid><description/></item><item><title>DeepImageJ: A user-friendly environment to run deep learning models in ImageJ</title><link>https://aicell.io/publication/gomez-2021-deepimagej/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/gomez-2021-deepimagej/</guid><description/></item><item><title>Interactive biomedical segmentation tool powered by deep learning and ImJoy</title><link>https://aicell.io/publication/ouyang-2021-interactive/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/ouyang-2021-interactive/</guid><description/></item><item><title>Pycro-Manager: open-source software for customized and reproducible microscope control</title><link>https://aicell.io/publication/pinkard-2021-pycro/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/pinkard-2021-pycro/</guid><description/></item><item><title>Super-resolution visualization and modeling of human chromosomal regions reveals cohesin-dependent loop structures</title><link>https://aicell.io/publication/hao-2021-super/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/hao-2021-super/</guid><description/></item><item><title>Welcome to Wowchemy, the website builder for Hugo</title><link>https://aicell.io/post/getting-started/</link><pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate><guid>https://aicell.io/post/getting-started/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ol>
&lt;li>The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site&lt;/li>
&lt;li>The template can be modified and customised to suit your needs. It&amp;rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a &lt;strong>no-code solution (write in Markdown and customize with YAML parameters)&lt;/strong> and having &lt;strong>flexibility to later add even deeper personalization with HTML and CSS&lt;/strong>&lt;/li>
&lt;li>You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more&lt;/li>
&lt;/ol>
&lt;figure id="figure-the-template-is-mobile-first-with-a-responsive-design-to-ensure-that-your-site-looks-stunning-on-every-device">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/wowchemy/wowchemy-hugo-modules/master/academic.png" alt="The template is mobile first with a responsive design to ensure that your site looks stunning on every device." loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
The template is mobile first with a responsive design to ensure that your site looks stunning on every device.
&lt;/figcaption>&lt;/figure>
&lt;h2 id="get-started">Get Started&lt;/h2>
&lt;ul>
&lt;li>ðŸ‘‰ &lt;a href="https://wowchemy.com/templates/" target="_blank" rel="noopener">&lt;strong>Create a new site&lt;/strong>&lt;/a>&lt;/li>
&lt;li>ðŸ“š &lt;a href="https://wowchemy.com/docs/" target="_blank" rel="noopener">&lt;strong>Personalize your site&lt;/strong>&lt;/a>&lt;/li>
&lt;li>ðŸ’¬ &lt;a href="https://discord.gg/z8wNYzb" target="_blank" rel="noopener">Chat with the &lt;strong>Wowchemy community&lt;/strong>&lt;/a> or &lt;a href="https://discourse.gohugo.io" target="_blank" rel="noopener">&lt;strong>Hugo community&lt;/strong>&lt;/a>&lt;/li>
&lt;li>ðŸ¦ Twitter: &lt;a href="https://twitter.com/wowchemy" target="_blank" rel="noopener">@wowchemy&lt;/a> &lt;a href="https://twitter.com/GeorgeCushen" target="_blank" rel="noopener">@GeorgeCushen&lt;/a> &lt;a href="https://twitter.com/search?q=%23MadeWithWowchemy&amp;amp;src=typed_query" target="_blank" rel="noopener">#MadeWithWowchemy&lt;/a>&lt;/li>
&lt;li>ðŸ’¡ &lt;a href="https://github.com/wowchemy/wowchemy-hugo-modules/issues" target="_blank" rel="noopener">Request a &lt;strong>feature&lt;/strong> or report a &lt;strong>bug&lt;/strong> for &lt;em>Wowchemy&lt;/em>&lt;/a>&lt;/li>
&lt;li>â¬†ï¸ &lt;strong>Updating Wowchemy?&lt;/strong> View the &lt;a href="https://wowchemy.com/docs/hugo-tutorials/update/" target="_blank" rel="noopener">Update Tutorial&lt;/a> and &lt;a href="https://wowchemy.com/updates/" target="_blank" rel="noopener">Release Notes&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="crowd-funded-open-source-software">Crowd-funded open-source software&lt;/h2>
&lt;p>To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.&lt;/p>
&lt;h3 id="-click-here-to-become-a-sponsor-and-help-support-wowchemys-future-httpswowchemycomplans">&lt;a href="https://wowchemy.com/plans/" target="_blank" rel="noopener">â¤ï¸ Click here to become a sponsor and help support Wowchemy&amp;rsquo;s future â¤ï¸&lt;/a>&lt;/h3>
&lt;p>As a token of appreciation for sponsoring, you can &lt;strong>unlock &lt;a href="https://wowchemy.com/plans/" target="_blank" rel="noopener">these&lt;/a> awesome rewards and extra features ðŸ¦„âœ¨&lt;/strong>&lt;/p>
&lt;h2 id="ecosystem">Ecosystem&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>&lt;a href="https://github.com/wowchemy/hugo-academic-cli" target="_blank" rel="noopener">Hugo Academic CLI&lt;/a>:&lt;/strong> Automatically import publications from BibTeX&lt;/li>
&lt;/ul>
&lt;h2 id="inspiration">Inspiration&lt;/h2>
&lt;p>&lt;a href="https://academic-demo.netlify.com/" target="_blank" rel="noopener">Check out the latest &lt;strong>demo&lt;/strong>&lt;/a> of what you&amp;rsquo;ll get in less than 10 minutes, or &lt;a href="https://wowchemy.com/user-stories/" target="_blank" rel="noopener">view the &lt;strong>showcase&lt;/strong>&lt;/a> of personal, project, and business sites.&lt;/p>
&lt;h2 id="features">Features&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Page builder&lt;/strong> - Create &lt;em>anything&lt;/em> with &lt;a href="https://wowchemy.com/docs/page-builder/" target="_blank" rel="noopener">&lt;strong>widgets&lt;/strong>&lt;/a> and &lt;a href="https://wowchemy.com/docs/content/writing-markdown-latex/" target="_blank" rel="noopener">&lt;strong>elements&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;strong>Edit any type of content&lt;/strong> - Blog posts, publications, talks, slides, projects, and more!&lt;/li>
&lt;li>&lt;strong>Create content&lt;/strong> in &lt;a href="https://wowchemy.com/docs/content/writing-markdown-latex/" target="_blank" rel="noopener">&lt;strong>Markdown&lt;/strong>&lt;/a>, &lt;a href="https://wowchemy.com/docs/import/jupyter/" target="_blank" rel="noopener">&lt;strong>Jupyter&lt;/strong>&lt;/a>, or &lt;a href="https://wowchemy.com/docs/install-locally/" target="_blank" rel="noopener">&lt;strong>RStudio&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;strong>Plugin System&lt;/strong> - Fully customizable &lt;a href="https://wowchemy.com/docs/customization/" target="_blank" rel="noopener">&lt;strong>color&lt;/strong> and &lt;strong>font themes&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;strong>Display Code and Math&lt;/strong> - Code highlighting and &lt;a href="https://en.wikibooks.org/wiki/LaTeX/Mathematics" target="_blank" rel="noopener">LaTeX math&lt;/a> supported&lt;/li>
&lt;li>&lt;strong>Integrations&lt;/strong> - &lt;a href="https://analytics.google.com" target="_blank" rel="noopener">Google Analytics&lt;/a>, &lt;a href="https://disqus.com" target="_blank" rel="noopener">Disqus commenting&lt;/a>, Maps, Contact Forms, and more!&lt;/li>
&lt;li>&lt;strong>Beautiful Site&lt;/strong> - Simple and refreshing one page design&lt;/li>
&lt;li>&lt;strong>Industry-Leading SEO&lt;/strong> - Help get your website found on search engines and social media&lt;/li>
&lt;li>&lt;strong>Media Galleries&lt;/strong> - Display your images and videos with captions in a customizable gallery&lt;/li>
&lt;li>&lt;strong>Mobile Friendly&lt;/strong> - Look amazing on every screen with a mobile friendly version of your site&lt;/li>
&lt;li>&lt;strong>Multi-language&lt;/strong> - 34+ language packs including English, ä¸­æ–‡, and PortuguÃªs&lt;/li>
&lt;li>&lt;strong>Multi-user&lt;/strong> - Each author gets their own profile page&lt;/li>
&lt;li>&lt;strong>Privacy Pack&lt;/strong> - Assists with GDPR&lt;/li>
&lt;li>&lt;strong>Stand Out&lt;/strong> - Bring your site to life with animation, parallax backgrounds, and scroll effects&lt;/li>
&lt;li>&lt;strong>One-Click Deployment&lt;/strong> - No servers. No databases. Only files.&lt;/li>
&lt;/ul>
&lt;h2 id="themes">Themes&lt;/h2>
&lt;p>Wowchemy and its templates come with &lt;strong>automatic day (light) and night (dark) mode&lt;/strong> built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the &lt;a href="https://academic-demo.netlify.com/" target="_blank" rel="noopener">Demo&lt;/a> to see it in action! Day/night mode can also be disabled by the site admin in &lt;code>params.toml&lt;/code>.&lt;/p>
&lt;p>&lt;a href="https://wowchemy.com/docs/customization" target="_blank" rel="noopener">Choose a stunning &lt;strong>theme&lt;/strong> and &lt;strong>font&lt;/strong>&lt;/a> for your site. Themes are fully customizable.&lt;/p>
&lt;h2 id="license">License&lt;/h2>
&lt;p>Copyright 2016-present &lt;a href="https://georgecushen.com" target="_blank" rel="noopener">George Cushen&lt;/a>.&lt;/p>
&lt;p>Released under the &lt;a href="https://github.com/wowchemy/wowchemy-hugo-modules/blob/master/LICENSE.md" target="_blank" rel="noopener">MIT&lt;/a> license.&lt;/p></description></item><item><title>Method, device, and computer program for improving the reconstruction of dense super-resolution images from diffraction-limited images acquired by single molecule localization microscopy</title><link>https://aicell.io/publication/zimmer-2020-method/</link><pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/zimmer-2020-method/</guid><description/></item><item><title>Mapping the nucleolar proteome reveals a spatiotemporal organization related to intrinsic protein disorder</title><link>https://aicell.io/publication/stenstrom-2020-mapping/</link><pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/stenstrom-2020-mapping/</guid><description/></item><item><title>Slides</title><link>https://aicell.io/slides/example/</link><pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate><guid>https://aicell.io/slides/example/</guid><description>&lt;h1 id="create-slides-in-markdown-with-wowchemy">Create slides in Markdown with Wowchemy&lt;/h1>
&lt;p>&lt;a href="https://wowchemy.com/" target="_blank" rel="noopener">Wowchemy&lt;/a> | &lt;a href="https://owchemy.com/docs/managing-content/#create-slides" target="_blank" rel="noopener">Documentation&lt;/a>&lt;/p>
&lt;hr>
&lt;h2 id="features">Features&lt;/h2>
&lt;ul>
&lt;li>Efficiently write slides in Markdown&lt;/li>
&lt;li>3-in-1: Create, Present, and Publish your slides&lt;/li>
&lt;li>Supports speaker notes&lt;/li>
&lt;li>Mobile friendly slides&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="controls">Controls&lt;/h2>
&lt;ul>
&lt;li>Next: &lt;code>Right Arrow&lt;/code> or &lt;code>Space&lt;/code>&lt;/li>
&lt;li>Previous: &lt;code>Left Arrow&lt;/code>&lt;/li>
&lt;li>Start: &lt;code>Home&lt;/code>&lt;/li>
&lt;li>Finish: &lt;code>End&lt;/code>&lt;/li>
&lt;li>Overview: &lt;code>Esc&lt;/code>&lt;/li>
&lt;li>Speaker notes: &lt;code>S&lt;/code>&lt;/li>
&lt;li>Fullscreen: &lt;code>F&lt;/code>&lt;/li>
&lt;li>Zoom: &lt;code>Alt + Click&lt;/code>&lt;/li>
&lt;li>&lt;a href="https://revealjs.com/pdf-export/" target="_blank" rel="noopener">PDF Export&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="code-highlighting">Code Highlighting&lt;/h2>
&lt;p>Inline code: &lt;code>variable&lt;/code>&lt;/p>
&lt;p>Code block:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">porridge&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;blueberry&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="n">porridge&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s2">&amp;#34;blueberry&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;Eating...&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="math">Math&lt;/h2>
&lt;p>In-line math: $x + y = z$&lt;/p>
&lt;p>Block math:&lt;/p>
&lt;p>$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p>
&lt;hr>
&lt;h2 id="fragments">Fragments&lt;/h2>
&lt;p>Make content appear incrementally&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">{{% fragment %}} One {{% /fragment %}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{{% fragment %}} **Two** {{% /fragment %}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{{% fragment %}} Three {{% /fragment %}}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Press &lt;code>Space&lt;/code> to play!&lt;/p>
&lt;span class="fragment " >
One
&lt;/span>
&lt;span class="fragment " >
&lt;strong>Two&lt;/strong>
&lt;/span>
&lt;span class="fragment " >
Three
&lt;/span>
&lt;hr>
&lt;p>A fragment can accept two optional parameters:&lt;/p>
&lt;ul>
&lt;li>&lt;code>class&lt;/code>: use a custom style (requires definition in custom CSS)&lt;/li>
&lt;li>&lt;code>weight&lt;/code>: sets the order in which a fragment appears&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="speaker-notes">Speaker Notes&lt;/h2>
&lt;p>Add speaker notes to your presentation&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-markdown" data-lang="markdown">&lt;span class="line">&lt;span class="cl">{{% speaker_note %}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">-&lt;/span> Only the speaker can read these notes
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">-&lt;/span> Press &lt;span class="sb">`S`&lt;/span> key to view
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {{% /speaker_note %}}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Press the &lt;code>S&lt;/code> key to view the speaker notes!&lt;/p>
&lt;aside class="notes">
&lt;ul>
&lt;li>Only the speaker can read these notes&lt;/li>
&lt;li>Press &lt;code>S&lt;/code> key to view&lt;/li>
&lt;/ul>
&lt;/aside>
&lt;hr>
&lt;h2 id="themes">Themes&lt;/h2>
&lt;ul>
&lt;li>black: Black background, white text, blue links (default)&lt;/li>
&lt;li>white: White background, black text, blue links&lt;/li>
&lt;li>league: Gray background, white text, blue links&lt;/li>
&lt;li>beige: Beige background, dark text, brown links&lt;/li>
&lt;li>sky: Blue background, thin dark text, blue links&lt;/li>
&lt;/ul>
&lt;hr>
&lt;ul>
&lt;li>night: Black background, thick white text, orange links&lt;/li>
&lt;li>serif: Cappuccino background, gray text, brown links&lt;/li>
&lt;li>simple: White background, black text, blue links&lt;/li>
&lt;li>solarized: Cream-colored background, dark green text, blue links&lt;/li>
&lt;/ul>
&lt;hr>
&lt;section data-noprocess data-shortcode-slide
data-background-image="/media/boards.jpg"
>
&lt;h2 id="custom-slide">Custom Slide&lt;/h2>
&lt;p>Customize the slide style and background&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-markdown" data-lang="markdown">&lt;span class="line">&lt;span class="cl">{{&lt;span class="p">&amp;lt;&lt;/span> &lt;span class="nt">slide&lt;/span> &lt;span class="na">background-image&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;/media/boards.jpg&amp;#34;&lt;/span> &lt;span class="p">&amp;gt;&lt;/span>}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{{&lt;span class="p">&amp;lt;&lt;/span> &lt;span class="nt">slide&lt;/span> &lt;span class="na">background-color&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;#0000FF&amp;#34;&lt;/span> &lt;span class="p">&amp;gt;&lt;/span>}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{{&lt;span class="p">&amp;lt;&lt;/span> &lt;span class="nt">slide&lt;/span> &lt;span class="na">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;my-style&amp;#34;&lt;/span> &lt;span class="p">&amp;gt;&lt;/span>}}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="custom-css-example">Custom CSS Example&lt;/h2>
&lt;p>Let&amp;rsquo;s make headers navy colored.&lt;/p>
&lt;p>Create &lt;code>assets/css/reveal_custom.css&lt;/code> with:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-css" data-lang="css">&lt;span class="line">&lt;span class="cl">&lt;span class="p">.&lt;/span>&lt;span class="nc">reveal&lt;/span> &lt;span class="nt">section&lt;/span> &lt;span class="nt">h1&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">.&lt;/span>&lt;span class="nc">reveal&lt;/span> &lt;span class="nt">section&lt;/span> &lt;span class="nt">h2&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">.&lt;/span>&lt;span class="nc">reveal&lt;/span> &lt;span class="nt">section&lt;/span> &lt;span class="nt">h3&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">color&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="kc">navy&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h1 id="questions">Questions?&lt;/h1>
&lt;p>&lt;a href="https://github.com/wowchemy/wowchemy-hugo-modules/discussions" target="_blank" rel="noopener">Ask&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://wowchemy.com/docs/managing-content/#create-slides" target="_blank" rel="noopener">Documentation&lt;/a>&lt;/p></description></item><item><title>Slides</title><link>https://aicell.io/slides/model-zoo/</link><pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate><guid>https://aicell.io/slides/model-zoo/</guid><description>&lt;h1 id="img-altbioimage-model-zoo-srchttpsbioimageiostaticimgbioimage-io-logo-whitesvg">&lt;img alt="BioImage Model Zoo" src="https://bioimage.io/static/img/bioimage-io-logo-white.svg">&lt;/h1>
&lt;p>Wei OUYANG&lt;/p>
&lt;p>SciLifeLab | KTH Royal Institute of Technology, Stockholm&lt;/p>
&lt;hr>
&lt;h3 id="httpsbioimageio">&lt;a href="https://bioimage.io" target="_blank" rel="noopener">https://bioimage.io&lt;/a>&lt;/h3>
&lt;img style="max-height: calc(100vh - 100px);" alt="BioImage Model Zoo screenshot" src="https://raw.githubusercontent.com/oeway/slides/master/2022/bioimage-model-zoo-screenshot.png">
&lt;hr>
&lt;h1 id="challenges">Challenges&lt;/h1>
&lt;ul>
&lt;li>Training models is difficult&lt;/li>
&lt;/ul>
&lt;ul>
&lt;li>Complex hardware/software setup&lt;/li>
&lt;li>Environmental impact: &amp;ldquo;Training a single AI model can emit as much carbon as five cars in their lifetimes&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;ul>
&lt;li>Lack of interoperability&lt;/li>
&lt;li>Hard for non-expert to run&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="bioimage-model-zoo">ðŸ¦’BioImage Model Zoo&lt;/h1>
&lt;ul>
&lt;li>AI model file standard&lt;/li>
&lt;li>Hosting pretrained models&lt;/li>
&lt;li>Test run service&lt;/li>
&lt;li>User/Developer services&lt;/li>
&lt;/ul>
&lt;hr>
&lt;!-- .slide: data-background="white" -->
&lt;h3 id="bioimage-model-zoo-overview">ðŸ¦’BioImage Model Zoo: Overview&lt;/h3>
&lt;img style="height:calc(100% - 200px);object-fit:contain;background-color: white;" src="https://docs.google.com/drawings/d/e/2PACX-1vRSNdb6sW-nrTjmHgqwG8sOTdQTjdNjWH0y4DveZwairx_NUKiHg3dm0-0Z7VU4ppFdwSiK2BLn4hKo/pub?w=1732&amp;amp;h=1343">
&lt;hr>
&lt;!-- .slide: data-background="white" -->
&lt;h3 id="how-it-works">ðŸ¤”How it works&lt;/h3>
&lt;img style="height:calc(100% - 200px);object-fit:contain;background-color: white;" src="https://docs.google.com/drawings/d/e/2PACX-1vSh8qO-jxZcGKjg5w52IMTesAUMbOaOxc3XQgmW7zBBj6btMGAUjcgh6iHgaTyzI18Ld7SSHkbie2k2/pub?w=1057&amp;amp;h=689">
&lt;hr>
&lt;h2 id="demos">ðŸ”¥Demos!&lt;/h2>
&lt;ul>
&lt;li>Overview: &lt;a href="https://bioimage.io/" target="_blank" rel="noopener">https://bioimage.io/&lt;/a>&lt;/li>
&lt;li>Find and download models&lt;/li>
&lt;li>Upload Models&lt;/li>
&lt;li>Ask for help&lt;/li>
&lt;/ul>
&lt;hr>
&lt;!-- .slide: data-background="white" -->
&lt;h2 id="meet-the-bioengine">Meet the BioEngine&lt;/h2>
&lt;img style="max-height: calc(100vh - 100px);" src="https://docs.google.com/drawings/d/e/2PACX-1vQCVUJDbgT_cPVsm--P75h13xbl7kW1Kt4RESW2opDb8MYOQrYQxToaFMFYdUwEBDBC4EWKwto0EExB/pub?w=1550&amp;amp;h=983">
&lt;hr>
&lt;!-- .slide: data-background="white" -->
&lt;h2 id="deploying-the-bioengine">Deploying the BioEngine&lt;/h2>
&lt;img src="https://docs.google.com/drawings/d/e/2PACX-1vSoG7ywI0qbNAbG-bV7J9LomhlK8r1xyhxS70LcA4_XNt_oUiWoYLcMFJlUFB2oA80hgL5TQzAWUhNW/pub?w=1510&amp;amp;h=1050">
&lt;hr>
&lt;h2 id="bioengine-feature-hightlights">BioEngine feature hightlights&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Many models&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Many users&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Many applications&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Shared GPU resources&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Both inference and training&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Local or cloud deployment&lt;/strong>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="bioengine-vs-jupyter-notebooks--colab">BioEngine vs Jupyter Notebooks / Colab&lt;/h2>
&lt;p>Scalability!&lt;/p>
&lt;ul>
&lt;li>Cloud &amp;amp; On-premise deployment&lt;/li>
&lt;li>For multi-user or the public&lt;/li>
&lt;li>Multi-model serving&lt;/li>
&lt;li>Improved GPU utilization&lt;/li>
&lt;li>Instant usage without setup or installation&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="accessing-the-bioengine-from-icy">Accessing the BioEngine from Icy&lt;/h2>
&lt;img src="https://raw.githubusercontent.com/oeway/slides/master/2022/icy-bioengine-cellpose-demo.gif">
&lt;p>Collabration with Carlos GarcÃ­a LÃ³pez de Haro and the Icy Team&lt;/p>
&lt;hr>
&lt;h2 id="accessing-the-bioengine-from-icy-1">Accessing the BioEngine from Icy&lt;/h2>
&lt;img src="https://raw.githubusercontent.com/oeway/slides/master/2022/icy-bioengine-demo-nuclei-segmentation.gif">
&lt;p>Collabration with Carlos GarcÃ­a LÃ³pez de Haro and the Icy Team&lt;/p>
&lt;hr>
&lt;h2 id="conclusions">Conclusions&lt;/h2>
&lt;ul>
&lt;li>AI model sharing via BioImage Model Zoo&lt;/li>
&lt;li>BioEninge for scalable AI model serving&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="acknowledgements-1">Acknowledgements (1)&lt;/h3>
&lt;p>Work carried out at Cell Profiling group @ SciLifeLab headed by Emma Lundberg&lt;/p>
&lt;p>BioImage.IO is powered by the ðŸ§  and â¤ï¸ of:&lt;/p>
&lt;ul>
&lt;li>deepImageJ Team&lt;/li>
&lt;li>EBI Bioimage Archive Team&lt;/li>
&lt;li>Fiji/ImageJ Team&lt;/li>
&lt;li>ilastik Team&lt;/li>
&lt;li>ImJoy Team&lt;/li>
&lt;li>ZeroCostDL4Mic Team&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;p>Follow us on twitter @bioimageio&lt;/p>
&lt;hr>
&lt;h1 id="thank-you">ðŸ™Thank You!&lt;/h1></description></item><item><title>Analysis of the human protein atlas image classification competition</title><link>https://aicell.io/publication/ouyang-2019-analysis/</link><pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/ouyang-2019-analysis/</guid><description/></item><item><title>ImJoy: an open-source computational platform for the deep learning era</title><link>https://aicell.io/publication/ouyang-2019-imjoy/</link><pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/ouyang-2019-imjoy/</guid><description/></item><item><title>A computational framework to study sub-cellular RNA localization</title><link>https://aicell.io/publication/samacoits-2018-computational/</link><pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/samacoits-2018-computational/</guid><description/></item><item><title>Deep learning massively accelerates super-resolution localization microscopy</title><link>https://aicell.io/publication/ouyang-2018-deep/</link><pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/ouyang-2018-deep/</guid><description/></item><item><title>IoT-based remote pain monitoring system: From device to cloud platform</title><link>https://aicell.io/publication/yang-2017-iot/</link><pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/yang-2017-iot/</guid><description/></item><item><title>The imaging tsunami: computational opportunities and challenges</title><link>https://aicell.io/publication/ouyang-2017-imaging/</link><pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate><guid>https://aicell.io/publication/ouyang-2017-imaging/</guid><description/></item><item><title/><link>https://aicell.io/admin/config.yml</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aicell.io/admin/config.yml</guid><description/></item><item><title>Doctoral Student in Cell Biology and Computational Microscopy Imaging</title><link>https://aicell.io/recruiting/phd-1-wasp-ddls-biology/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aicell.io/recruiting/phd-1-wasp-ddls-biology/</guid><description>&lt;p>Title: Doctoral Student in Cell Biology and Computational Microscopy Imaging&lt;/p>
&lt;p>KTH Royal Institute of Technology in Stockholm has grown to become one of Europe&amp;rsquo;s leading technical and engineering universities, as well as a key centre of intellectual talent and innovation. We are Sweden&amp;rsquo;s largest technical research and learning institution and home to students, researchers and faculty from around the world. Our research and education covers a wide area including natural sciences and all branches of engineering, as well as architecture, industrial management, urban planning, history and philosophy.&lt;/p>
&lt;h3 id="project-description">Project description&lt;/h3>
&lt;p>Third-cycle subject: Biological Physics&lt;/p>
&lt;p>The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research. The combination of the highly interdisciplinary expertise and research projects at the department is unique in Sweden and also at an international level. This expertise ranges across cell biology, biochemistry, biophysics and theory. Recently, the SciLifeLab and Wallenberg National Program started the &lt;a href="https://www.scilifelab.se/data-driven/" target="_blank" rel="noopener">Data-Driven Life Science (DDLS) program&lt;/a> in order to accelerate life science research through innovations in AI and data science.&lt;/p>
&lt;p>&lt;a href="https://oeway.github.io" target="_blank" rel="noopener">Wei Ouyang&lt;/a>&amp;rsquo;s research group at the department of Applied Physics, KTH and SciLifeLab is a newly funded lab through the DDLS Fellows program. The group focuses on building AI systems for data-driven cell and molecular biology, and is inviting applications for a doctoral student position in biological physics with a focus on cell biology, automation and AI-augmented microscopy imaging.&lt;/p>
&lt;p>Whole-cell modeling enables a holistic and quantitative view of cell biology and allows performing in-silico experimentation which has a great potential in revolutionizing system biology, synthetic biology, medicine and other applications in life science. However, modeling the entire cell is an extremely complex task and is heavily limited by our understanding of the biological systems. As a newly formed research group, we would like to take the grand challenge of modeling the human cell through recent advances in artificial intelligence and multi-omics data generation. To enable large-scale AI and data-driven whole cell modeling, we are currently building a smart microscopy imaging farm to ramp up the production rate of image data. The imaging farm consists of multiple microscopes and fluidic systems, robotic arms, liquid handling robots and automatic incubators. The farm will be used for performing automated brightfield/fluorescence imaging, long-term live cell imaging, tracking,Â  spatial-omics and multiplexing imaging. For the whole-cell modeling project, we aim to build an AI-powered automated imaging system to actively detect, monitor and track the live human cells under drug and genetic perturbations. We would like to develop AI models which read changes in cell morphology and fluorescence markers, to generate control signals for driving the microscope, capture rare events and create balanced dataset for modeling.&lt;/p>
&lt;p>You will be responsible for actively and effectively designing and implementing wet lab experiments in the imaging farm, including cell culture, sample preparation and microscopy imaging. Importantly, you will also actively work with other researchers in the group to develop and adapt protocols for the automated imaging farm and AI models. Besides wet lab skills, you will elaborate on your computational skills, e.g., by writing Python scripts to control the imaging farm, train AI models and develop automated data analysis workflows. In later stages of the project you will also design and conduct additional, custom validation experiments, which may involve different molecular biology techniques.&lt;/p>
&lt;h2 id="supervision-professor-hjalmar-brismar-and-assistant-professor-wei-ouyang-are-proposed-to-supervise-the-doctoral-student-decisions-are-made-on-admission">Supervision: Professor Hjalmar Brismar and Assistant Professor Wei Ouyang are proposed to supervise the doctoral student. Decisions are made on admission.&lt;/h2>
&lt;h2 id="what-we-offer">What we offer&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>The possibility to study in a dynamic and international research environment in collaboration with industries and prominent universities from all over the world. &lt;a href="https://www.kth.se/en/studies/phd/why-1.521017" target="_blank" rel="noopener">Read more&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A workplace with &lt;a href="https://www.kth.se/en/om/work-at-kth/en-arbetsplats-med-manga-formaner-1.467932" target="_blank" rel="noopener">many employee benefits&lt;/a> and monthly salary according to &lt;a href="https://intra.kth.se/en/anstallning/anstallningsvillkor/lon/doktorandstegen-1.572915" target="_blank" rel="noopener">KTH&amp;rsquo;s Doctoral student salary agreement&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A postgraduate education at an institution that is active and supportive in matters pertaining to working conditions, gender equality and diversity as well as study environment.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Work and study in Stockholm, close to nature and the water.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Learning and thriving in a young and ambitious research group&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Help to&lt;a href="https://www.kth.se/en/om/work-at-kth/relocation" target="_blank" rel="noopener"> relocate and be settled in Sweden and at KTH&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="admission-requirements">Admission requirements&lt;/h2>
&lt;p>To be admitted to postgraduate education (Chapter 7, 39 Â§ Swedish Higher Education Ordinance), the applicant must have basic eligibility in accordance with either of the following:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>passed a second cycle degree (for example a master&amp;rsquo;s degree), or&lt;/p>
&lt;/li>
&lt;li>
&lt;p>completed course requirements of at least 240 higher education credits, of which at least 60 second-cycle higher education credits, or&lt;/p>
&lt;/li>
&lt;li>
&lt;p>acquired, in some other way within or outside the country, substantially equivalent knowledge&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Type in the special eligibility the applicant also shall meet.&lt;/p>
&lt;p>In addition to the above, there is also a mandatory requirement for English equivalent to English B/6,Â &lt;a href="https://www.kth.se/en/studies/phd/admission-requirements-1.520175" target="_blank" rel="noopener">read more here&lt;/a>&lt;/p>
&lt;h2 id="selection">SelectionÂ &lt;/h2>
&lt;p>In order to succeed as a doctoral student at KTH you need to be goal oriented and persevering in your work. During the selection process, candidates will be assessed upon their ability to:Â &lt;/p>
&lt;ul>
&lt;li>
&lt;p>independently pursue his or her work,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>collaborate with others,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>work comfortable in an interdisciplinary team,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>have a professional approach,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>analyse and work with complex issues,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>demonstrate a solid understanding in cell and molecular biology,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>demonstrate prior experience with cell culture, molecular biology, microscopy imaging and other wet lab skills,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>demonstrate prior experience with developing, establishing, optimizing, and trouble-shootingwet lab protocols,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>cross disciplines, and demonstrate a passion for lab automation, AI and other computational skills,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>acquired basic skills in programming languages such as Python and R.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Prior experience in data analysis workflow development and machine learning is beneficial.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>After the qualification requirements, great emphasis will be placed on personal competency.&lt;/p>
&lt;p>Target degree: Doctoral degree&lt;/p>
&lt;h2 id="information-regarding-admission-and-employment">Information regarding admission and employment&lt;/h2>
&lt;p>Only those admitted to postgraduate education may be employed as a doctoral student. The total length of employment may not be longer than what corresponds to full-time doctoral education in four years &amp;rsquo; time. An employed doctoral student can, to a limited extent (maximum 20%), perform certain tasks within their role, e.g. training and administration. A new position as a doctoral student is for a maximum of one year, and then the employment may be renewed for a maximum of two years at a time.&lt;/p>
&lt;h2 id="union-representatives">Union representatives&lt;/h2>
&lt;p>You will find contact information for union representatives on &lt;a href="https://intra.kth.se/en/administration/rekrytering/annonsering/fackrepresentanter-1.500898" target="_blank" rel="noopener">KTH&amp;rsquo;s website&lt;/a>.&lt;/p>
&lt;h2 id="doctoral-section-students-union-on-kth-royal-institute-of-technology">Doctoral section (Students&amp;rsquo; union on KTH Royal Institute of Technology)&lt;/h2>
&lt;p>You will find contact information for doctoral section on the &lt;a href="https://www.dr.kth.se/" target="_blank" rel="noopener">section&amp;rsquo;s website&lt;/a>.&lt;/p>
&lt;h2 id="application">Application&lt;/h2>
&lt;p>Apply for the position and admission through KTH&amp;rsquo;s recruitment system. It is the applicant&amp;rsquo;s responsibility to ensure that the application is complete in accordance with the instructions in the advertisement.&lt;/p>
&lt;p>Applications must be received at the last closing date at midnight, CET/CEST (Central European Time/Central European Summer Time).&lt;/p>
&lt;p>Applications must include the following elements:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>CV including your relevant professional experience and knowledge.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Application letter with a brief description of why you want to pursue research studies, about what your academic interests are and how they relate to your previous studies and future goals. (Maximum 2 pages long).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Copies of diplomas and grades from previous university studies and certificates of fulfilled &lt;a href="https://www.kth.se/en/studies/phd/admission-requirements-1.520175" target="_blank" rel="noopener">language requirements (see above).&lt;/a> Translations into English or Swedish if the original document is not issued in one of these languages. Copies of originals must be &lt;a href="https://www.kth.se/en/student/framtid/examen/verifiering/vidimering-av-handlingar-1.55190" target="_blank" rel="noopener">certified&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Representative publications or technical reports: For longer documents, please provide a summary (abstract) and a web link to the full text.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="other">Other&lt;/h2>
&lt;p>Striving towards gender equality, diversity and equal conditions is both a question of quality for KTH and a given part of our values.Â &lt;/p>
&lt;p>For informationÂ about processing of personal data in the recruitment process &lt;a href="https://www.kth.se/en/om/work-at-kth/processing-of-personal-data-in-the-recruitment-process-1.823440" target="_blank" rel="noopener">please read here.&lt;/a>&lt;/p></description></item><item><title>Postdoc in AI-powered Automated Microscopy Imaging Systems</title><link>https://aicell.io/recruiting/postdoc-1-ddls-enginering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aicell.io/recruiting/postdoc-1-ddls-enginering/</guid><description>&lt;p>Title: Postdoc in AI-powered Automated Microscopy Imaging Systems&lt;/p>
&lt;p>Job description&lt;/p>
&lt;p>The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research. The combination of the highly interdisciplinary expertise and research projects at the department is unique in Sweden and also at an international level. This expertise ranges across cell biology, biochemistry, biophysics and theory. Recently, the SciLifeLab and Wallenberg National Program started the &lt;a href="https://www.scilifelab.se/data-driven/" target="_blank" rel="noopener">Data-Driven Life Science (DDLS) program&lt;/a> in order to accelerate life science research through innovations in AI and data science.&lt;/p>
&lt;p>&lt;a href="https://oeway.github.io" target="_blank" rel="noopener">Wei Ouyang&lt;/a>&amp;rsquo;s research group at the department of Applied Physics, KTH and SciLifeLab is a newly funded lab through the DDLS Fellows program. The group focuses on building AI systems for data-driven cell and molecular biology, and is now seeking a postdoctoral researcher to develop AI-powered automated microscopy imaging systems.&lt;/p>
&lt;p>The aim of the project is to build a smart microscopy imaging farm for massive production of image data. It consists of multiple microscopes and fluidic systems, robotic arms, liquid handling robots and automatic incubators. The farm will be used for performing automated widefield/fluorescence imaging, long-term live cell imaging, tracking,Â  spatial-omics and multiplexing imaging. With the AI-powered control software, data are analyzed in real-time, augmented views are added on the fly. By generating feedback control signals to control the microscope, the software will automatically change field-of-views, illumination power and other experimental conditions in order to optimize the phototoxicity and capture rare events in live cells.&lt;/p>
&lt;p>The candidate is expected to develop an integrated system with microscopes, fluidic control, robotic arms, as well as the control software. The project is a collaboration with our collaborator within the &lt;a href="https://wasp-sweden.org/" target="_blank" rel="noopener">WASP program&lt;/a> and built on top of our prior work (e.g. squid microscopes, &lt;a href="https://www.nature.com/articles/s41592-019-0627-0" target="_blank" rel="noopener">ImJoy&lt;/a>) from us or our collaborators.&lt;/p>
&lt;p>What we offerÂ &lt;/p>
&lt;ul>
&lt;li>
&lt;p>A position at a leading technical university that generates knowledge and skills for a sustainable future.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Engaged and ambitious colleagues along with a creative, international and dynamic working environment&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Works in Stockholm, in close proximity to nature&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Collaboration opportunities with leading research institutions and universities in Europe and the US&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Learning and thriving in a young and ambitious research group&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Help to&lt;a href="https://www.kth.se/en/om/work-at-kth/relocation" target="_blank" rel="noopener"> relocate and be settled in Sweden and at KTH&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://www.kth.se/en/om/work-at-kth/kth-your-future-workplace-1.49050" target="_blank" rel="noopener">Read more about what it is like to work at KTH&lt;/a>&lt;/p>
&lt;p>Qualifications&lt;/p>
&lt;p>Requirements&lt;/p>
&lt;ul>
&lt;li>
&lt;p>A doctoral degree or an equivalent foreign degree, This eligibility requirement must be met no later than the time the employment decision is made.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The ability to express yourself in English.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Preferred qualifications&lt;/p>
&lt;ul>
&lt;li>
&lt;p>You are passionate, curious and knowledgeable on developing automated systems&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Strong background in electronics, optics and mechanical engineering&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Proficient in programming languages such as Python and C/C++, Javascript, Bash&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Prior experience in building microscopes, fluidics and robotics systems&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Prior experience in building AI models, MLops and tools&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Knowledge in cell biology&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Knowledge in digital image analysis and computer vision&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Knowledge in web technologies (e.g. network communication, browser standards, containerization and kubernetes)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Knowledge in software design, web services and distributed computing systems&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Collaborative abilities, and scientific communicationÂ &lt;/p>
&lt;/li>
&lt;li>
&lt;p>Awareness of diversity and equal opportunity issues, with a specific focus on gender equality&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Great emphasis will be placed on personal competency&lt;/p>
&lt;p>Trade union representatives&lt;/p>
&lt;p>You will find contact information to trade union representatives at &lt;a href="https://intra.kth.se/en/administration/rekrytering/annonsering/fackrepresentanter-1.500898" target="_blank" rel="noopener">KTH.se&lt;/a>&lt;/p>
&lt;p>Application&lt;/p>
&lt;p>Log into KTH&amp;rsquo;s recruitment system in order to apply to this position. You are responsible to ensure that your application is complete according to the instructions in the ad.&lt;/p>
&lt;p>The application must include:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>CV including relevant professional experience, knowledge and representative publications. Please also provide your Github/Gitlab/Bitbucket etc. handle if possible.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Copy of diplomas and grades from your previous university studies. Translations into English or Swedish if the original documents have not been issued in any of these languages.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Brief account of why you want to conduct research, your career goal and how they relate to your previous studies and future goals. Max two pages long.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Your complete application must be received by KTH no later than the last day of application, midnight&lt;/p>
&lt;p>CET/CEST (Central European Time/Central European Summer Time).&lt;/p>
&lt;p>About the employment&lt;/p>
&lt;p>The position offered is for, at the most, two years. There may be possibilities to prolong employment.&lt;/p>
&lt;p>A position as a postdoctoral fellow is a time-limited qualified appointment focusing mainly on research, intended as a first career step after a dissertation.&lt;/p>
&lt;p>Other information&lt;/p>
&lt;p>Striving towards gender equality, diversity and equal conditions is both a question of quality for KTH and a given part of our values.&lt;br>
For informationÂ about processing of personal data in the recruitment process &lt;a href="https://www.kth.se/en/om/work-at-kth/processing-of-personal-data-in-the-recruitment-process-1.823440" target="_blank" rel="noopener">please read here.&lt;/a>&lt;/p></description></item><item><title>Postdoc in AI-powered multi-omics data integration and whole-cell modeling</title><link>https://aicell.io/recruiting/postdoc-2-ddls-ai/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aicell.io/recruiting/postdoc-2-ddls-ai/</guid><description>&lt;p>Title: Postdoc in AI-powered multi-omics data integration and whole-cell modeling.&lt;/p>
&lt;p>Job description&lt;/p>
&lt;p>The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research. The combination of the highly interdisciplinary expertise and research projects at the department is unique in Sweden and also at an international level. This expertise ranges across cell biology, biochemistry, biophysics and theory. Recently, the SciLifeLab and Wallenberg National Program started the &lt;a href="https://www.scilifelab.se/data-driven/" target="_blank" rel="noopener">Data-Driven Life Science (DDLS) program&lt;/a> in order to accelerate life science research through innovations in AI and data science.&lt;/p>
&lt;p>&lt;a href="https://oeway.github.io" target="_blank" rel="noopener">Wei Ouyang&lt;/a>&amp;rsquo;s research group at the department of Applied Physics, KTH and SciLifeLab is a newly funded lab through the DDLS Fellows program. The group focuses on building AI systems for data-driven cell and molecular biology, and is now seeking two postdoctoral researchers to build AI systems for spatial multi-omics data analysis and whole-cell modeling.&lt;/p>
&lt;p>Whole-cell modeling enables a holistic and quantitative view of cell biology and allows performing in-silico experimentation which has a great potential in revolutionizing system biology, synthetic biology, medicine and other applications in life science. However, modeling the entire cell is an extremely complex task and is heavily limited by our understanding of the biological systems. As a newly formed research group, we would like to take the grand challenge of modeling the human cell through recent advances in multi-omics data generation and artificial intelligence. Our aim is to use recent deep learning techniques such as convolutional neural networks, transformers, AlphaFold and diffusion models to analysis existing multi-omics dataset, combining them with massive amount of newly generated live cell, multiplexed images, to model cellular behavior through generative and predictive models.&lt;/p>
&lt;p>The candidates are expected to 1) develop machine learning models and tools for smart microscopy and image analysis 2) integrate multi-omics dataset 3) perform generative modeling and 4) create large-scale differentiable models to do spatial cell simulations. The project will be carried out on top of existing work and collaborate closely with PhDs and postdocs in the group.&lt;/p>
&lt;p>What we offerÂ &lt;/p>
&lt;ul>
&lt;li>
&lt;p>A position at a leading technical university that generates knowledge and skills for a sustainable future.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Engaged and ambitious colleagues along with a creative, international and dynamic working environment&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Works in Stockholm, in close proximity to nature&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Collaboration opportunities with leading research institutions and universities in Europe and the US&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Learning and thriving in a young and ambitious research group&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Help to&lt;a href="https://www.kth.se/en/om/work-at-kth/relocation" target="_blank" rel="noopener"> relocate and be settled in Sweden and at KTH&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://www.kth.se/en/om/work-at-kth/kth-your-future-workplace-1.49050" target="_blank" rel="noopener">Read more about what it is like to work at KTH&lt;/a>&lt;/p>
&lt;p>Qualifications&lt;/p>
&lt;p>Requirements&lt;/p>
&lt;ul>
&lt;li>
&lt;p>A doctoral degree or an equivalent foreign degree, This eligibility requirement must be met no later than the time the employment decision is made.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The ability to express yourself in English.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Preferred qualifications&lt;/p>
&lt;ul>
&lt;li>
&lt;p>You are passionate and knowledgeable on developing and applying machine learning models to life science applications&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Proficient in programming languages such as Python, understanding cloud and web computing technologies is a plus&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Training in cell and molecular biology&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Wet lab experience in cell and molecular biology&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Prior experience in bioimage analysis, genomics sequence analysis, protein folding and metabolic network analysis&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Prior experience in cell modeling and simulation&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Prior experience in fluorescence microscopy imaging&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Prior experience in building deep learning models and tools, microscopy control, software design, web services and distributed computing systems&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Knowledge in popular neural networks architectures, natural language processing models, generative models, AlphaFold&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Collaborative abilities&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Awareness of diversity and equal opportunity issues, with a specific focus on gender equality&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Great emphasis will be placed on personal competency&lt;/p>
&lt;p>Trade union representatives&lt;/p>
&lt;p>You will find contact information to trade union representatives at &lt;a href="https://intra.kth.se/en/administration/rekrytering/annonsering/fackrepresentanter-1.500898" target="_blank" rel="noopener">KTH.se&lt;/a>&lt;/p>
&lt;p>Application&lt;/p>
&lt;p>Log into KTH&amp;rsquo;s recruitment system in order to apply to this position. You are responsible to ensure that your application is complete according to the instructions in the ad.&lt;/p>
&lt;p>The application must include:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>CV including relevant professional experience, knowledge and representative publications. Please also provide your Github/Gitlab/Bitbucket etc. handle if possible.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Copy of diplomas and grades from your previous university studies. Translations into English or Swedish if the original documents have not been issued in any of these languages.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Brief account of why you want to conduct research, your career goal and how they relate to your previous studies and future goals. Max two pages long.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Your complete application must be received by KTH no later than the last day of application, midnight&lt;/p>
&lt;p>CET/CEST (Central European Time/Central European Summer Time).&lt;/p>
&lt;p>About the employment&lt;/p>
&lt;p>The position offered is for, at the most, two years. There may be possibilities to prolong the employment.&lt;/p>
&lt;p>A position as a postdoctoral fellow is a time-limited qualified appointment focusing mainly on research, intended as a first career step after a dissertation.&lt;/p>
&lt;p>Other information&lt;/p>
&lt;p>Striving towards gender equality, diversity and equal conditions is both a question of quality for KTH and a given part of our values.&lt;br>
For informationÂ about processing of personal data in the recruitment process &lt;a href="https://www.kth.se/en/om/work-at-kth/processing-of-personal-data-in-the-recruitment-process-1.823440" target="_blank" rel="noopener">please read here.&lt;/a>&lt;/p></description></item><item><title>Postdoc in Cell Biology and Computational Microscopy Imaging</title><link>https://aicell.io/recruiting/postdoc-1-wasp-ddls-biology/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aicell.io/recruiting/postdoc-1-wasp-ddls-biology/</guid><description>&lt;p>Job description&lt;/p>
&lt;p>The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research. The combination of the highly interdisciplinary expertise and research projects at the department is unique in Sweden and also at an international level. This expertise ranges across cell biology, biochemistry, biophysics and theory. Recently, the SciLifeLab and Wallenberg National Program started the &lt;a href="https://www.scilifelab.se/data-driven/" target="_blank" rel="noopener">Data-Driven Life Science (DDLS) program&lt;/a> in order to accelerate life science research through innovations in AI and data science.&lt;/p>
&lt;p>&lt;a href="https://oeway.github.io" target="_blank" rel="noopener">Wei Ouyang&lt;/a>&amp;rsquo;s research group at the department of Applied Physics, KTH and SciLifeLab is a newly funded lab through the DDLS Fellows program. The group focuses on building AI systems for data-driven cell and molecular biology, and is looking for highly motivated candidates to fill a 2-year postdoc position under the &lt;a href="https://www.scilifelab.se/data-driven/wasp-collaboration/" target="_blank" rel="noopener">WASP-DDLS collaboration&lt;/a>.&lt;/p>
&lt;p>The aim of the project is to develop an AI-powered self-driving microscopy system for studying cellular response under genetic and environmental stressors. The project will also be supported by the WASP-DDLS collaboration, and closely collaborate with the JaldÃ©n group at KTH. The JaldÃ©n group has rich experience in computer vision and automatic control systems. The work will also be supported by the Lundberg group under the Human Protein Atlas, which is a unique world-leading effort to map all the human proteins in cells, tissues, and organs in the human body. By joining the force with the JaldÃ©n group and Lundberg group, we would like to develop an AI-powered imaging system to continuously monitor, actively acquire and track human cells under different cellular and environmental stressors. The data will be used to train large-scale AI models to study cellular responses and make predictions for cell fate.&lt;/p>
&lt;p>You will be responsible for actively and effectively designing, implementing, and optimizingÂ  wet lab experiments for the self-driving microscope, including cell culture, sample preparation and microscopy imaging. Importantly, you will also actively work with other researchers in the group to develop and optimize protocols for the automated imaging system and AI models. Besides wet lab skills, you will get the opportunity to elaborate on your computational skills, e.g., by writing Python scripts to control the imaging farm, train AI models and develop automated data analysis workflows. In later stages of the project you will also design and conduct additional, custom validation experiments, which may involve different molecular biology techniques.&lt;/p>
&lt;p>What we offerÂ &lt;/p>
&lt;ul>
&lt;li>
&lt;p>A position at a leading technical university that generates knowledge and skills for a sustainable future.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Engaged and ambitious colleagues along with a creative, international and dynamic working environment&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Works in Stockholm, in close proximity to nature&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Collaboration opportunities with leading research institutions and universities in Europe and the US&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Learning and thriving in a young and ambitious research group&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Help to&lt;a href="https://www.kth.se/en/om/work-at-kth/relocation" target="_blank" rel="noopener"> relocate and be settled in Sweden and at KTH&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://www.kth.se/en/om/work-at-kth/kth-your-future-workplace-1.49050" target="_blank" rel="noopener">Read more about what it is like to work at KTH&lt;/a>&lt;/p>
&lt;p>Qualifications&lt;/p>
&lt;p>Requirements&lt;/p>
&lt;ul>
&lt;li>
&lt;p>A doctoral degree or an equivalent foreign degree, This eligibility requirement must be met no later than the time the employment decision is made.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The ability to express yourself in English.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Preferred qualifications&lt;/p>
&lt;p>During the selection process, candidates will be assessed upon their ability to:Â &lt;/p>
&lt;ul>
&lt;li>
&lt;p>independently pursue his or her work,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>collaborate with others,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>supervise junior people in the lab (e.g., internship and undergraduate students)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>to conceptualize and write publications and scientific reports,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>clearly present scientific concepts and data,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>work comfortable in an interdisciplinary team,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>have a professional approach,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>analyse and work with complex issues,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>have a solid understanding in cell and molecular biology,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>demonstrate prior experience with cell culture, molecular biology, high throughput microscopy imaging and other wet lab skills, preferably experience with automated liquid handlers or similar instruments,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>demonstrate prior experience with developing, establishing, optimizing, and trouble-shootingwet lab protocols,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>cross disciplines, and demonstrate a passion for lab automation, AI and other computational skills,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>demonstrate prior experience in programming languages such as Python and R.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Prior experience in data analysis workflow development and machine learning is beneficial.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Great emphasis will be placed on personal competency&lt;/p>
&lt;p>Trade union representatives&lt;/p>
&lt;p>You will find contact information to trade union representatives at &lt;a href="https://intra.kth.se/en/administration/rekrytering/annonsering/fackrepresentanter-1.500898" target="_blank" rel="noopener">KTH.se&lt;/a>&lt;/p>
&lt;p>Application&lt;/p>
&lt;p>Log into KTH&amp;rsquo;s recruitment system in order to apply to this position. You are responsible to ensure that your application is complete according to the instructions in the ad.&lt;/p>
&lt;p>The application must include:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>CV including relevant professional experience, knowledge and representative publications. Please also provide your Github/Gitlab/Bitbucket etc. handle if possible.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Copy of diplomas and grades from your previous university studies. Translations into English or Swedish if the original documents have not been issued in any of these languages.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Brief account of why you want to conduct research, your career goal and how they relate to your previous studies and future goals. Max two pages long.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Your complete application must be received by KTH no later than the last day of application, midnight&lt;/p>
&lt;p>CET/CEST (Central European Time/Central European Summer Time).&lt;/p>
&lt;p>About the employment&lt;/p>
&lt;p>The position offered is for, at the most, two years. There may be possibilities to prolong the employment.&lt;/p>
&lt;p>A position as a postdoctoral fellow is a time-limited qualified appointment focusing mainly on research, intended as a first career step after a dissertation.&lt;/p>
&lt;p>Other information&lt;/p>
&lt;p>Striving towards gender equality, diversity and equal conditions is both a question of quality for KTH and a given part of our values.&lt;br>
For informationÂ about processing of personal data in the recruitment process &lt;a href="https://www.kth.se/en/om/work-at-kth/processing-of-personal-data-in-the-recruitment-process-1.823440" target="_blank" rel="noopener">please read here.&lt;/a>&lt;/p></description></item><item><title>Postdoc in Scalable AI Systems for BioImage Analysis</title><link>https://aicell.io/recruiting/postdoc-1-ai4life/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aicell.io/recruiting/postdoc-1-ai4life/</guid><description>&lt;p>Title: Postdoc in Scalable AI Systems for BioImage Analysis&lt;/p>
&lt;h3 id="job-description">Job description&lt;/h3>
&lt;p>&lt;a href="https://ai4life.eurobioimaging.eu/" target="_blank" rel="noopener">AI4Life&lt;/a> is an EU funded project which aims to empower life science researchers to harness the full potential of AI and machine learning methods for bioimage analysis. As one of the leading partners in the consortium, we are hiring a postdoctoral researcher at the department of applied physics, KTH Royal Institute of Technology.&lt;/p>
&lt;p>The postdoc will join a newly formed research group led by &lt;a href="https://oeway.github.io/" target="_blank" rel="noopener">Wei Ouyang&lt;/a> and work with other AI4Life consortium partners to build scalable AI tools and computing infrastructure for bioimage analysis. There are two aims in the project: 1) Creating web services and computing platforms for sharing AI models, making them more accessible and usable; 2) Building scalable bioimage analysis methods and tools for powering next-generation &lt;a href="https://www.sciencedirect.com/science/article/pii/S0092867418304562" target="_blank" rel="noopener">augmented microscopy&lt;/a>. This includes creating tools for collaborative and interactive annotation, model training, real-time inference and generating feedback signal for microscope control.&lt;/p>
&lt;p>The candidates are expected to collaborate with other AI4Life partners and develop scalable AI methods, tools and platforms on top of our prior work such as the &lt;a href="https://www.biorxiv.org/content/10.1101/2022.06.07.495102v1" target="_blank" rel="noopener">BioImage Model Zoo&lt;/a> and &lt;a href="https://www.nature.com/articles/s41592-019-0627-0" target="_blank" rel="noopener">ImJoy&lt;/a>.&lt;/p>
&lt;h3 id="what-we-offer">What we offerÂ &lt;/h3>
&lt;ul>
&lt;li>
&lt;p>A position at a leading technical university that generates knowledge and skills for a sustainable future.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Engaged and ambitious colleagues along with a creative, international and dynamic working environment&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Works in Stockholm, in close proximity to nature&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Collaboration opportunities with leading research institutions and universities in Europe and the US&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Learning and thriving in a young and ambitious research group&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Help to&lt;a href="https://www.kth.se/en/om/work-at-kth/relocation" target="_blank" rel="noopener"> relocate and be settled in Sweden and at KTH&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://www.kth.se/en/om/work-at-kth/kth-your-future-workplace-1.49050" target="_blank" rel="noopener">Read more about what it is like to work at KTH&lt;/a>&lt;/p>
&lt;h3 id="qualifications">Qualifications&lt;/h3>
&lt;h3 id="requirements">Requirements&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>A doctoral degree or an equivalent foreign degree, This eligibility requirement must be met no later than the time the employment decision is made.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The ability to express yourself in English.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="preferred-qualifications">Preferred qualifications&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>You are passionate, curious and knowledgeable on developing web services and tools&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Proficient in programming languages such as Python and Javascript, Bash&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Proficient in web technologies (e.g. network communication, browser standards, containerization and kubernetes)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Prior experience in building AI models, MLops and tools&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Knowledge in digital image analysis and computer vision&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Knowledge in software design, web services and distributed computing systems&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Collaborative abilities, and scientific communicationÂ &lt;/p>
&lt;/li>
&lt;li>
&lt;p>Awareness of diversity and equal opportunity issues, with a specific focus on gender equality&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Great emphasis will be placed on personal competency&lt;/p>
&lt;h3 id="trade-union-representatives">Trade union representatives&lt;/h3>
&lt;p>You will find contact information to trade union representatives at &lt;a href="https://intra.kth.se/en/administration/rekrytering/annonsering/fackrepresentanter-1.500898" target="_blank" rel="noopener">KTH.se&lt;/a>&lt;/p>
&lt;h3 id="application">Application&lt;/h3>
&lt;p>Log into KTH&amp;rsquo;s recruitment system in order to apply to this position. You are responsible to ensure that your application is complete according to the instructions in the ad.&lt;/p>
&lt;p>The application must include:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>CV including relevant professional experience, knowledge and representative publications. Please also provide your Github/Gitlab/Bitbucket etc. handle if possible.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Copy of diplomas and grades from your previous university studies. Translations into English or Swedish if the original documents have not been issued in any of these languages.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Brief account of why you want to conduct research, your career goal and how they relate to your previous studies and future goals. Max two pages long.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Your complete application must be received by KTH no later than the last day of application, midnight&lt;/p>
&lt;p>CET/CEST (Central European Time/Central European Summer Time).&lt;/p>
&lt;h3 id="about-the-employment">About the employment&lt;/h3>
&lt;p>The position offered is for, at the most, two years. There may be possibilities to prolong employment.&lt;/p>
&lt;p>A position as a postdoctoral fellow is a time-limited qualified appointment focusing mainly on research, intended as a first career step after a dissertation.&lt;/p>
&lt;h3 id="other-information">Other information&lt;/h3>
&lt;p>Striving towards gender equality, diversity and equal conditions is both a question of quality for KTH and a given part of our values.&lt;br>
For informationÂ about processing of personal data in the recruitment process &lt;a href="https://www.kth.se/en/om/work-at-kth/processing-of-personal-data-in-the-recruitment-process-1.823440" target="_blank" rel="noopener">please read here.&lt;/a>&lt;/p></description></item></channel></rss>